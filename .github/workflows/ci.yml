name: CI

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements-dev.txt
    
    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 src --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings
        flake8 src --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    - name: Check formatting with black
      run: |
        black --check src

  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ['3.10', '3.11']
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Cache HuggingFace models
      uses: actions/cache@v3
      with:
        path: ~/.cache/huggingface
        key: ${{ runner.os }}-huggingface-${{ hashFiles('src/utils/hf_model_cache.py') }}
        restore-keys: |
          ${{ runner.os }}-huggingface-
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y libgl1-mesa-glx libglib2.0-0
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
    
    - name: Download HuggingFace models (if not cached)
      run: |
        python -c "
        from src.utils.hf_model_cache import HFModelLoader
        loader = HFModelLoader(local_only=False)
        # Pre-download tiny model for tests
        loader.load_model('tiny')
        " || echo "HF model download failed, will use local_only mode in tests"
      continue-on-error: true
      env:
        HF_HUB_OFFLINE: 0
    
    - name: Run tests
      run: |
        pytest src/tests/ -v --cov=src --cov-report=xml --cov-report=term
      env:
        HF_HUB_OFFLINE: 1  # Use offline mode during tests
        TRANSFORMERS_OFFLINE: 1
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  test-cuda:
    runs-on: ubuntu-latest
    # Only run CUDA tests when explicitly requested (requires self-hosted runner with GPU)
    if: contains(github.event.head_commit.message, '[test-cuda]')
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install torch torchvision --index-url https://download.pytorch.org/whl/cu130
        pip install -r requirements.txt
        pip install -r requirements-dev.txt
    
    - name: Run CUDA tests
      run: |
        pytest src/tests/ -v -m "not slow" --cov=src
